'use strict';

import { createError, IDB_ERROR } from 'pouchdb-errors';
import { collectConflicts } from 'pouchdb-merge';

import { DOC_STORE, processAttachment } from './util';

function allDocsKeys(keys, docStore, allDocsInner) {
  // It's not guaranteed to be returned in right order
  var valuesBatch = new Array(keys.length);
  var count = 0;
  keys.forEach(function (key, index) {
    docStore.get(key).onsuccess = function (event) {
      if (event.target.result) {
      valuesBatch[index] = event.target.result;
      } else {
        valuesBatch[index] = {key, error: 'not_found'};
      }
      count++;
      if (count === keys.length) {
        valuesBatch.forEach(function (doc) {
            allDocsInner(doc);
        });
      }
    };
  });
}

function createKeyRange(start, end, inclusiveEnd, key, descending) {
  try {
    if (key) {
      return IDBKeyRange.only([0, key]);
    } else if (descending) {
      return IDBKeyRange.bound(end, start, !inclusiveEnd, false);
    } else {
      return IDBKeyRange.bound(start, end, false, !inclusiveEnd);
    }
  } catch (e) {
    return {error: e};
  }
}

function handleKeyRangeError(opts, metadata, err, callback) {
  if (err.name === "DataError" && err.code === 0) {
    // data error, start is less than end
    var returnVal = {
      total_rows: metadata.doc_count,
      offset: opts.skip,
      rows: []
    };
    /* istanbul ignore if */
    if (opts.update_seq) {
      returnVal.update_seq = metadata.seq;
    }
    return callback(null, returnVal);
  }
  callback(createError(IDB_ERROR, err.name, err.message));
}

export default function (txn, metadata, opts, callback) {
  if (txn.error) {
    return callback(txn.error);
  }

  // TODO: Weird hack, I don't like it
  if (opts.limit === 0) {
    var returnVal = {
      total_rows: metadata.doc_count,
      offset: opts.skip,
      rows: []
    };

    /* istanbul ignore if */
    if (opts.update_seq) {
      returnVal.update_seq = metadata.seq;
    }
    return callback(null, returnVal);
  }

  var results = [];
  var processing = [];

  var key = 'key' in opts ? opts.key : false;
  var keys = 'keys' in opts ? opts.keys : false;
  var skip = opts.skip || 0;
  var limit = typeof opts.limit === 'number' ? opts.limit : undefined;
  var inclusiveEnd = opts.inclusive_end !== false;
  var descending = 'descending' in opts && opts.descending ? 'prev' : null;
  var start = 'startkey' in opts ? opts.startkey : (descending ?  '\uffff' : '');
  var end   = 'endkey'   in opts ? opts.endkey   : (descending ? '' :  '\uffff');

  var docStore = txn.txn.objectStore(DOC_STORE);

  if (keys) {
    txn.txn.oncomplete = onTxnComplete;
    const allDocsInner = doc => {
      if (doc.error) {
        return results.push(doc);
      }

      const row = { id:doc.id, key:doc.id, value:{ rev:doc.rev } };

      if (doc.deleted) {
        row.value.deleted = true;
        row.doc = null;
      } else if (opts.include_docs) {
        include_doc(row, doc);
      }

      results.push(row);
    };
    return allDocsKeys(keys, docStore, allDocsInner);
  }

  let keyRange = createKeyRange([0, start], [0, end], inclusiveEnd, key, descending);
  if (keyRange.error) {
    return handleKeyRangeError(opts, metadata, keyRange.error, callback);
  }

  // txn.oncomplete must be set AFTER key-range-error is generated
  txn.txn.oncomplete = onTxnComplete;

  function include_doc(row, doc) {
    var docData = doc.revs[doc.rev].data;

    row.doc = docData;
    row.doc._id = doc.id;
    row.doc._rev = doc.rev;
    if (opts.conflicts) {
      var conflicts = collectConflicts(doc);
      if (conflicts.length) {
        row.doc._conflicts = conflicts;
      }
    }
    if (opts.attachments && docData._attachments) {
      for (var name in docData._attachments) {
        processing.push(processAttachment(name, doc, row.doc, opts.binary,
            metadata.idb_attachment_format));
      }
    }
  }

  function onTxnComplete() {
    const returnVal = {
      total_rows: metadata.doc_count,
      offset: 0,
      rows: results
    };
    /* istanbul ignore if */
    if (opts.update_seq) {
      returnVal.update_seq = metadata.seq;
    }

    if (processing.length) {
      Promise.all(processing).then(function () {
        callback(null, returnVal);
      });
    } else {
      callback(null, returnVal);
    }
  }

  const dbIndex = docStore.index('_isDeleted_id');

  if (skip) {
    dbIndex.openKeyCursor(keyRange, descending || 'next').onsuccess = (e) => {
      const cursor = e.target.result;
      if (!cursor) {
        return txn.txn.commit();
      }

      if (skip) {
        cursor.advance(skip);
        skip = 0;
        return;
      }

      const lastSkipped = cursor.key;
      if (lastSkipped === undefined) {
        // no results
        return txn.txn.commit();
      }

      // At this point, existing keyRange bounds are already compound keys.
      if (descending) {
        keyRange = createKeyRange(lastSkipped, keyRange.lower, inclusiveEnd, key, descending);
      } else {
        keyRange = createKeyRange(lastSkipped, keyRange.upper, inclusiveEnd, key, descending);
      }
      if (keyRange.error) {
        txn.txn.abort();
        return handleKeyRangeError(opts, metadata, keyRange.error, callback);
      }

      fetchResults();
    };
  } else {
    fetchResults();
  }

  function fetchResults() {
    // REVIEW: there is a risk here with getting all results into memory - if they have multiple
    // revs, then we risk loading loads of extra data which is then discarded.  This could be
    // reduced with batching.
    // REVIEW: this also loads a lot of unused data when include_docs is false.  The fastest and
    // most pragmatic approach here may be batching...
    if (descending && limit) {
      // getAll() does not support descending, so this can either be implemented with a cursor, or
      // by calling getAll(), iterating from the top, and discarding.  It is currently using the
      // latter approach, but may need thought and optimisation
      dbIndex.getAll(keyRange).onsuccess = (e) => {
        const values = e.target.result;
        for (let i=values.length-1; i>=0 && limit--; --i) {
          const doc = values[i];
          const row = { id:doc.id, key:doc.id, value:{ rev:doc.rev } };
          if (opts.include_docs) {
            include_doc(row, doc);
          }
          results[values.length - i - 1] = row;
        }
        return txn.txn.commit();
      };
    } else {
      dbIndex.getAll(keyRange, limit).onsuccess = (e) => {
        const values = e.target.result;
        for (let i=0; i<values.length; ++i) {
          const doc = values[descending ? values.length-i-1 : i];
          const row = { id:doc.id, key:doc.id, value:{ rev:doc.rev } };
          if (opts.include_docs) {
            include_doc(row, doc);
          }
          results[i] = row;
        }
        return txn.txn.commit();
      };
    }
  }
}
